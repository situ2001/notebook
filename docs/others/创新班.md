# 创新班

## 第一次survey

### FGSM & TensorFlow

Note: **Fast Gradient Signed Method (FGSM)**

记录了阅读TensorFlow官方中的一篇[tutorial](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm)

因为这次survey我选择了第三个课题，里面建议可以去参加一些如阿里天池的比赛，我选择了ImageNet这个赛道了，得到5000张图片之后，就是要进行一定的处理，来对黑盒进行攻击。我去寻找往期的，找到了似乎是学长的一篇分享，里面有它们所用到的源码:[Github repo](https://github.com/Donald-Su/19-TianChi-Attack-ImageNet?spm=5176.12282029.0.0.3f9d3416ZHr8qM)

#### 简介

有一些重要的东西，记录一下

什么是对抗图片呢?这个tutorial如是说

> Adversarial examples are specialized inputs created with the purpose of confusing a neural network, resulting in the misclassification of a given input. These notorious inputs are indistinguishable to the human eye, but cause the network to fail to identify the contents of the image.

简的来说就是通过把一些人眼觉察不到的如噪点，加到这幅图片上，使得机器对图片的识别分类产生错误。

这个算法使用如下的公式

$$adv\_x = x + \epsilon*\text{sign}(\nabla_xJ(\theta, x, y))$$

* adv_x : Adversarial image.
* x : Original input image.
* y : Original input label.
* $\epsilon$ : Multiplier to ensure the perturbations are small.
* $\theta$ : Model parameters.
* $J$ : Loss.

第一眼看下去，公式看不懂...有什么特别的呢？

> An intriguing property here, is the fact that the gradients are taken **with respect to the input image**. This is done because the objective is to create an image that maximizes the loss. A method to accomplish this is to **find how much each pixel in the image contributes to the loss value**, and add a perturbation accordingly. This works pretty **fast** because it is easy to find how each input pixel contributes to the loss by using the chain rule and finding the required gradients. Hence, the gradients are taken with respect to the image.

？他这里说，这个算法是通过根据每一个输入图片本身来决定**gradient**的大小的，而由于这个特性，导致这个算法工作起来快一点。

#### 实操

到了我最喜欢的实践部分，下面记录了我一步步跟着tutorial做实践的笔记。这里使用的是经过pre-trained的MMobileNetV2模型。

跟着tutorial走的话，大致的操作是分为这么几个

1. 加载预训练好了的模型与ImageNet上面的标签（应该是用于classification的）
2. 加载图片并对图片进行predicate
3. 使用tf实现FGSM方法
4. 生成对抗样本图像

详细地来讲一下

首先是第一步，很明显的调库，不用多说了

``` python
# Preparation
import tensorflow as tf
import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rcParams['figure.figsize'] = (8, 8)
mpl.rcParams['axes.grid'] = False

# Load pretrained MoblieV2 model
pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,
                                                     weights='imagenet')
pretrained_model.trainable = False

# And the ImageNet name
# ImageNet labels
decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions
```

然后是第二步，加载图片

``` python
# Helper function to preprocess the image so that it can be inputted in MobileNetV2
def preprocess(image):
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, (224, 224))
  image = tf.keras.applications.mobilenet_v2.preprocess_input(image)
  image = image[None, ...]
  return image

# Helper function to extract labels from probability vector
def get_imagenet_label(probs):
  return decode_predictions(probs, top=1)[0][0]

# Download and load the picture from Internet
image_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')
image_raw = tf.io.read_file(image_path)
image = tf.image.decode_image(image_raw)
```

使用现成模型进行对图片的predicate

``` python
image = preprocess(image) # process the picture
image_probs = pretrained_model.predict(image) # use pretrained model to predicate the picture

# Glance a look to the picture downloaded just now
plt.figure()
plt.imshow(image[0]*0.5+0.5) # To change [-1, 1] to [0,1]
_, image_class, class_confidence = get_imagenet_label(image_probs)
plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))
plt.show()
```

实现FGSM method

``` python
# implement the FGSM method
loss_object = tf.keras.losses.CategoricalCrossentropy()

def create_adversarial_pattern(input_image, input_label):
  with tf.GradientTape() as tape:
    tape.watch(input_image)
    prediction = pretrained_model(input_image)
    loss = loss_object(input_label, prediction)

  # Get the gradients of the loss w.r.t to the input image.
  gradient = tape.gradient(loss, input_image)
  # Get the sign of the gradients to create the perturbation
  signed_grad = tf.sign(gradient)
  return signed_grad
```

生成perturbations并进行预览

``` python
# Get the input label of the image.
labrador_retriever_index = 208
label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])
label = tf.reshape(label, (1, image_probs.shape[-1]))

perturbations = create_adversarial_pattern(image, label)
plt.imshow(perturbations[0]*0.5+0.5); # To change [-1, 1] to [0,1]
plt.show()
```

定义display_images()函数并调节不同大小的$\epsilon$

``` python
# Show the adversarialed picture
def display_images(image, description):
  _, label, confidence = get_imagenet_label(pretrained_model.predict(image))
  plt.figure()
  plt.imshow(image[0]*0.5+0.5)
  plt.title('{} \n {} : {:.2f}% Confidence'.format(description,
                                                   label, confidence*100))
  plt.show()

# test in difference ranges
epsilons = [0, 0.01, 0.1, 0.15]
descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')
                for eps in epsilons]

for i, eps in enumerate(epsilons):
  adv_x = image + eps*perturbations
  adv_x = tf.clip_by_value(adv_x, -1, 1)
  display_images(adv_x, descriptions[i])
```
