# 创新班

## 第一次survey

### FGSM & TensorFlow

Note: **Fast Gradient Signed Method (FGSM)**

记录了阅读TensorFlow官方中的一篇[tutorial](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm)

因为这次survey我选择了第三个课题，里面建议可以去参加一些如阿里天池的比赛，我选择了ImageNet这个赛道了，得到5000张图片之后，就是要进行一定的处理，来对黑盒进行攻击。我去寻找往期的，找到了似乎是学长的一篇分享，里面有它们所用到的源码:[Github repo](https://github.com/Donald-Su/19-TianChi-Attack-ImageNet?spm=5176.12282029.0.0.3f9d3416ZHr8qM)

#### 简介

有一些重要的东西，记录一下

什么是对抗图片呢?这个tutorial如是说

> Adversarial examples are specialized inputs created with the purpose of confusing a neural network, resulting in the misclassification of a given input. These notorious inputs are indistinguishable to the human eye, but cause the network to fail to identify the contents of the image.

简的来说就是通过把一些人眼觉察不到的如噪点，加到这幅图片上，使得机器对图片的识别分类产生错误。

这个算法使用如下的公式

$$adv\_x = x + \epsilon*\text{sign}(\nabla_xJ(\theta, x, y))$$

* adv_x : Adversarial image.
* x : Original input image.
* y : Original input label.
* $\epsilon$ : Multiplier to ensure the perturbations are small.
* $\theta$ : Model parameters.
* $J$ : Loss.

第一眼看下去，公式看不懂...有什么特别的呢？

> An intriguing property here, is the fact that the gradients are taken **with respect to the input image**. This is done because the objective is to create an image that maximizes the loss. A method to accomplish this is to **find how much each pixel in the image contributes to the loss value**, and add a perturbation accordingly. This works pretty **fast** because it is easy to find how each input pixel contributes to the loss by using the chain rule and finding the required gradients. Hence, the gradients are taken with respect to the image.

？他这里说，这个算法是通过根据每一个输入图片本身来决定**gradient**的大小的，而由于这个特性，导致这个算法工作起来快一点。

#### 实操

到了我最喜欢的实践部分，下面记录了我一步步跟着tutorial做实践的笔记。

